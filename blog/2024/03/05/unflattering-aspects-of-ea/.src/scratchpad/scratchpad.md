## 2. Here are my previous naïve hopes about what EA could have been

Here are a few possible structural organizations EA could have had:

1. A competent army that is able to figure out where each person can do the most good and deploy them in that position—imagine the Illuminati, some idealized version of the US military, or an up-and-coming startup.
2. A decentralized cell model, where different subgroups organize and carry out their own designs, perhaps funded by their own members and guided by their own determinations—think an anarchist cell model trying to act robustly in enemy territory, development of the Linux kernel[^linux], [Direct Action Everywhere](https://en.wikipedia.org/wiki/Direct_Action_Everywhere).
3. A bureaucracy that has some notional goals but is staffed by fallible humans and pursuing its goals slowly and imperfectly—imagine your average government agency, a large & sclerotic company, the Catholic Church, etc.

[^linux]: Linux has both centralized and decentralized features. In terms of centralization, you have the fact that Linus Torvalds ultimately decides what goes in. In terms of decentralization, you have the fact that anyone can contribute, package it, fork it, improve it. I think that the centralization aspects would hurt and be more salient if Linus was incompetent and/or stringent, but as is, he seems competent and laid back enough that he can enable and channel a wide community around Linux, rather than holding it back. Note, though, that this is my impression from a distance, and the reader is welcome to take this as a pointer to how a social movement could work. Though e.g., tools like git *do* enable decentralized cooperation.

I think that personally, I would have hoped to encounter option 1. I think EA may have a remanent perception of itself as number 2, from back when it was a small social movement. And the parts of EA that frustrate me the most are when it behaves like number 3.

---


Here are some more right-wing coded flavours of effective altruism: 

- Effective capitalism: Capitalism has been a powerful engine for progress, and companies like Musk's SpaceX are at the forefront of pushing humanity further. Build scalable companies that produce vast amounts of goods, capture some of that profit, and scale up. 
  - Keep in mind Goodhart's law, though, and don't become evil; to make that easier, consider bootstrapping instead of taking VC funding, and not taking your company public.
  - Structuring things as a business instead of as a charity allows you to cease to depend on 
- Renewal in American politics: Biden => decay, promising upstarts like Ron de Santis, Vivek Ramaswamy, or Nikky Hailey. Working for their campaign tropecientos QALYs. If they are elected, but also if they end up belonging in a second Trump administration. Particulary if Ramaswamy 

---

# 

---

### 6. The whole thing is a very specific, US-American, Elizabeth Warren type of lefty

You start out wanting to do the most good, and you end up with this specific

- Effective Altruism women's wine night
- petite burgeoisie
- harvoring bored middle class people who want to feel like they are contributing to a cause

Flavour of mistakes that they make: criminal justice reform.

---

So you want to do some good. But do you want to be chasing Open Philanthropy funding and submitting yourself to their designs? Or do you have a better alternative? Could you grow rich independently, and then use your fortune 

There is this hope of "working for an EA org", which ultimately cashes out in terms of: working for an org that has seduced a billionnaire to 

---

## Borrowed power

## Discussion of alternatives

- Drink the cool aid
- EA as a trading partner. Build good 
- Eat what you kill
- Earn to give => Earn to build / earn to 
  - earn to control
  - earn to free yourself from the shackles
  - earn to buy yourself a shot at greatness
  - earn in preparation for a startup
  - earn to X
  - earn to uild an empire
  - earn to become independent
- Eat what you kill
- Improve the world through capitalism

## Conclusion

## Footnotes


---

Iterated games, where the EA machinery has chosen to go one way, and as a result I'm recommending that it now makes sense to do something subtly different from EA.

Mention above over community health.

The community health banned a friend over 
- My impression was that they did not communicate fairly, investigate enough. Ask for his perspective.
- Hostile to republicans.

---



TODO: rerun analysis but for longtermism.

Misha says: Nietzche says: Judge the philosophy by the philosopher. If can't find it attribute to Misha. 

As a small but personally important illustration of me not having much control, consider the Effective Altruism Forum. I used to be a prolific poster on the EA Forum, but over the last two years or so it became a shittier experience for me: more pushy, sluggy and censorious. Here then, I have various options:

- Nag[^nag]. Shout into [the void](https://twitter.com/NunoSempere/status/1589968170953363456), hope that my complaints are addressed.
- Mitigate. For example, I can create my [own frontend](https://forum.nunosempere.com/), which I can customize as I will. 
- Exit. Help build different and smaller communities, where my greater involvement means that I will have more of a voice. Go out on my own, have my own blog. 

to-do: think about whether this is a strong example. Are the forecasting or worldview diversification examples stronger?

[^nag]: Here are a few more cases of me nagging in the past: [over Open Philanthropy's funding of criminal justice reform not making sense to me](https://forum.effectivealtruism.org/posts/h2N9qEbvQ6RHABcae/a-critical-review-of-open-philanthropy-s-bet-on-criminal), [over EA not having forms of quantification beyond global health](https://forum.effectivealtruism.org/posts/3hH9NRqzGam65mgPG/five-steps-for-quantifying-speculative-interventions), [over "worldview diversification" not being a great framework](https://nunosempere.com/blog/2023/04/25/worldview-diversification/), [over Rethink Priorities' welfare range estimates not looking plausible](https://nunosempere.com/blog/2023/02/19/bayesian-adjustment-to-rethink-priorities-welfare-range-estimates/). 

---

- You have little power
- You won't have much real power. I have felt that I'm reduced to nagging.
- [x] Slow to trust, promotion to incompetence. 
- [ ] Early community members have more power. 
- Qualify yourself to the old ones
- Open Philanthropy is an imperfect organization
  - surprisingly milquetoast. 
  - Hufflepuff vs Slytherin / Ravenclaw
  - Inconsistent 
- The community doesn't care about you
  - Suggests that you should aim for higher salary, 
  - Make sure your outside option is good.
  - Make sure you can leave.
- The lens through which OP sees the world is through organizations

## Conclusion

Do I feel like contributing my soul and energy to a project with opaque leaders, milquetoast optimization power.

[ ] Doing something subtly different from EA. Ignore the implicit vibes and expectations that the Moskovitz

Take their funding, do your own thing.

Still, there is much to learn abou the EA ediffice.

- You start trying to do the most good you can do, and you end up doing the same petite-bourgeoisie shit everyone else in your demographic is doing

- The community is beholden [footnote: pun intended] to the source of funding.

Feedback loops such
- Not able to incorporate criticism

I can't tell who the captain at the ship of EA is
No org taking responsability
Too slow to trust => Predictable problems
Surprising number of constraints
Hostility towards conservatives


---


Some negative aspects of EA to think through whether you want to devote your heart and soul to it
===========================================================

## Introduction

Smth smeth propaganda.

## Considerations

### EA is a monopsony

One organization, Open Philanthropy, isn't 

### It is just not that hardcore

### It is not that competent

Blistering, white hot competence.

### It is pretty lefty

### There is an inner circle

## Conclusion

- Convenient source of funding
- Don't take leaps of faith
- Don't get sucked into the community

If you are really exceptional, you are probably better off doing your own thing.

Learn what you can.

Milquetoast

Hypocrisy about 

I have no power here.

Something about epistemics?

---

Recommendation: If you are talented, it's probably ok to develop an association with EA as one of various bets, but it's not worth it at this time to put all your eggs in one basket. 

Burning your youth in the pursuit of making the world a better place is something beautiful. EA may not be able to support you.

Chasing the girl

Fuck shrimp. Do something subtly different from EA-the-meme, or from the expectations of EA-the-Moskovitz-funding flow, but which better accords with your true values.

In my case, this might correspond to forecasting & speculative longtermism.

---

Understand what you are getting into, rather than getting into a dream that overpromises and underdelivers.

--- 

Leadership uderstands themselves accountable to the money, not to the community

I guess I'm disappointed at this because the community appeals and attracts nerds, but then places them in a position where high social skills are required. 

Add more specific examples.

Not being in the loop

Consider whether your outside option in fact was better

Doing a startup vs selling your soul to the VCs

---

"EA asks me to navigate a complex social web, with gatekeepers, interests and conflicts on the way to having an impact. But that's just not the kind of cog that I cam:.
Can't ignore it, because then I actualy od not have an impact.
I think with great effort, I can have some odels of OP, but I'm just not going to be great at it.
Winning move might be not to play
The only way to get real power is to build smth yourself
The court of Moskovitz the Magnanimous

---

## Related dynamics about those who have the reins on funding being slow to trust

Imposes costs, but not on those making the decisions

## Feedback loops aren't

- Cause investigations contest only within global health
- Karnofsky sort of decided that public feedback was low quality when he was running a small operation. Also didn't incentivize it.
- What is the mechanism by which EA/Open Philanthropy changes its mind? I draw a blank. 

## Hostility towards conservatives

## No blistering, white hot competence

## Inner circle dynamics

## There are twenty playable characters in EA, and you're not one of them

## Optimizers are dangerous used to constrain others, but not the inner circle

This is a pet peeve

## Chasing the girl

You will be chasing the girl, and the girl is Open Philanthropy funding

---

Here are my 

Iterated game, in which Open Philanthropy has disrespected the community, and so the correct move is for the community to disrespect. Stag game.

A core of good. In comparison with alternatives.


---

As a small but personally important illustration of the points, I used to be a prolific poster on the EA Forum, but over the last two years or so it became a shittier experience for me: more pushy[^pushy], sluggly [^sluggy] and censorious[^censor] website. Here, I have various options:

[^pushy]: It now has many more recommendations, pinned posts, curations, sidebars & shit.

[^sluggy]: takes ~5 seconds to load. 

[^censorious]: They have banned 3-4 people which were being disagreeable that I liked.

- Nag: Shout into [the void](https://twitter.com/NunoSempere/status/1589968170953363456)
- Mitigate: I can create my [own frontend](https://forum.nunosempere.com/), which I can customize as I will. 
- Exit: Go out on my own, have my own blog. Help build different and smaller communities, where my greater involvement means that I will have more of a voice.

---


~Things which should be common knowledge in EA
- Climate change probably not effective

A brief sketch of anti-climate change arguments

How I would design EA.

What you are buying is robustness.

See also some notes somewhere.

---

A moment of manic creation, followed by a process of making the output of the manic creation useful

---

I can fit almost anything in this research project. If I want to write a piece about Knightian uncertainty and forecasting, I can!
